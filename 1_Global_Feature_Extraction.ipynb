{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3f9796",
   "metadata": {},
   "source": [
    "# Machine Learning in Network Science\n",
    "Group Challenge\n",
    "\n",
    "***\n",
    "by: Leonardo Basili, Paul Bédier, Lasse Schmidt\n",
    "\n",
    "within: MS Data Sciences & Business Analytics\n",
    "\n",
    "at: CentraleSupélec & ESSEC Business School\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a46be5a",
   "metadata": {},
   "source": [
    "This notebook covers global graph feature extraction such as Rooted Pagerank and SimRank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f241a1",
   "metadata": {},
   "source": [
    "### 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98e82605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util.autoencoder' from 'c:\\\\Users\\\\lasse\\\\OneDrive\\\\Dokumente\\\\2_Bildung\\\\2_MSc\\\\1_Classes\\\\Y2T2_Machine Learning in Network Science\\\\4_challenge (git)\\\\Network-Science_Challenge\\\\util\\\\autoencoder.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(analyseData)\n",
    "reload(prepData)\n",
    "reload(loadData)\n",
    "reload(modeling)\n",
    "reload(autoenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ffae4f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# import own scripts\n",
    "import util.analyse_Data as analyseData\n",
    "import util.preprocess_Data as prepData\n",
    "import util.load_Data as loadData\n",
    "import util.modeling as modeling\n",
    "import util.autoencoder as autoenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7c6ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic stuff\n",
    "from itertools import product, combinations\n",
    "from collections import OrderedDict\n",
    "\n",
    "# parse & handle data\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx # graph data\n",
    "import sknetwork\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c682248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive edges for training: 4174\n",
      "Number of positive edges for validation: 1043\n",
      "Number of edges in original graph: 5217\n",
      "Number of edges in training graph: 4174\n",
      "The graph is connected\n",
      "Enriching train data...\n",
      "Enriching validation data...\n",
      "Enriching test data...\n"
     ]
    }
   ],
   "source": [
    "# might take up to a few minutes\n",
    "(G, G_train, node_info,\n",
    " train_tf, val_tf, trainval_tf,\n",
    " test, test_tf,\n",
    " X_train, y_train, X_val, y_val, X_trainval, y_trainval,\n",
    " X_test) = loadData.load_transform(testing_ratio = 0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74f20e78",
   "metadata": {},
   "source": [
    "### 2. Rooted Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f3a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_save_rooted_pagerank_json(G, df, damp, eps, trainval = False):\n",
    "    # create dictionary to store result\n",
    "    res = dict()\n",
    "\n",
    "    # compute rooted pagerank\n",
    "    pagerank = {root: prepData.rooted_pagerank(G, root, d = damp, epsilon = eps) for root in sorted(df.node1.unique())}\n",
    "\n",
    "    # only store the edges we actually need in result dict\n",
    "    for u, v in zip(df.node1, df.node2):\n",
    "        res[str(u)+\"_\"+str(v)] = pagerank[u][v]\n",
    "\n",
    "    # save in json file\n",
    "    if trainval:\n",
    "        fname = f\"rooted_pagerank_trainval_d{str(int(damp*100))}_eps{str(eps)}.json\"\n",
    "    else:\n",
    "        fname = f\"rooted_pagerank_test_d{str(int(damp*100))}_eps{str(eps)}.json\"\n",
    "\n",
    "    with open(\"data/\" + fname, \"w\") as file:\n",
    "        json.dump(res, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77d4e4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pagerank using damp 0.5 and eps 0.0001...\n",
      "Computing pagerank using damp 0.5 and eps 1e-06...\n",
      "Computing pagerank using damp 0.75 and eps 0.0001...\n",
      "Computing pagerank using damp 0.75 and eps 1e-06...\n",
      "Computing pagerank using damp 0.9 and eps 0.0001...\n",
      "Computing pagerank using damp 0.9 and eps 1e-06...\n",
      "Computing pagerank using damp 0.95 and eps 0.0001...\n",
      "Computing pagerank using damp 0.95 and eps 1e-06...\n",
      "Computing pagerank using damp 0.99 and eps 0.0001...\n",
      "Computing pagerank using damp 0.99 and eps 1e-06...\n"
     ]
    }
   ],
   "source": [
    "# search space\n",
    "dampening_facts = [0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "eps = [1e-4, 1e-6]\n",
    "\n",
    "# create rooted page rank using different hyperparams\n",
    "for damp in dampening_facts:\n",
    "    for e in eps:\n",
    "        print(f\"Computing pagerank using damp {damp} and eps {e}...\")\n",
    "\n",
    "        # trainval edges\n",
    "        compute_save_rooted_pagerank_json(G_train, trainval_tf, damp = damp, eps = e, trainval = True)\n",
    "\n",
    "        # test edges\n",
    "        compute_save_rooted_pagerank_json(G, test_tf, damp = damp, eps = e, trainval = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "056959e1",
   "metadata": {},
   "source": [
    "Let us now find the best hyperparameters of our rooted pagerank by validating each of them with our supervised model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d13eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names of the files\n",
    "fnames_trainval, fnames_test = [], []\n",
    "\n",
    "# used search space\n",
    "dampening_facts = [0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "eps = [1e-4, 1e-6]\n",
    "\n",
    "# get names\n",
    "for damp in dampening_facts:\n",
    "    for e in eps:\n",
    "        fnames_trainval.append(f\"data/rooted_pagerank_trainval_d{str(int(damp*100))}_eps{str(e)}.json\")\n",
    "        fnames_test.append(f\"data/rooted_pagerank_test_d{str(int(damp*100))}_eps{str(e)}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8ec1053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(df, cols, method, thresh):\n",
    "    # we assume that all metrics get better with increasing values!\n",
    "    \n",
    "    df_ = df[list(cols)]\n",
    "    \n",
    "    if method == \"rank_avg\":\n",
    "        df_ = df_.rank(pct = True).mean(axis = 1)  \n",
    "    elif method == \"avg\":\n",
    "        df_ = df_.mean(axis = 1)\n",
    "    elif method == \"whitened_sigmoid_avg\":\n",
    "        df_ = pd.DataFrame({col: sknetwork.linkpred.whitened_sigmoid(df_[col].to_numpy()) for col in df_.columns})\n",
    "        df_ = df_.mean(axis = 1)\n",
    "        \n",
    "    if thresh == \"top50%\":\n",
    "        y_hat = (df_ > df_.median()).astype(int)\n",
    "    elif thresh == \"thresh\":\n",
    "        y_hat = (df_ > 0.5).astype(int)\n",
    "    elif thresh == \"return_probas\":\n",
    "        y_hat = df_.rank(pct = True)\n",
    "        \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "695a304a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 71.44it/s]\n",
      "1it [00:00, 119.50it/s]\n",
      "1it [00:00, 123.20it/s]\n",
      "1it [00:00, 143.11it/s]\n",
      "1it [00:00, 145.05it/s]\n",
      "1it [00:00, 140.89it/s]\n",
      "1it [00:00, 142.60it/s]\n",
      "1it [00:00, 167.36it/s]\n",
      "1it [00:00, 166.69it/s]\n",
      "1it [00:00, 166.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# where we will store result\n",
    "res = OrderedDict()\n",
    "\n",
    "# search space\n",
    "dampening_facts = [0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "eps = [1e-4, 1e-6]\n",
    "\n",
    "# create rooted page rank using different hyperparams\n",
    "for (trainval, test, (damp, e)) in zip(fnames_trainval, fnames_test, product(dampening_facts, eps)):\n",
    "\n",
    "    # read json files for rank algorithms\n",
    "    with open(trainval, \"r\") as file:\n",
    "        r_pgr_trainval = json.load(file)\n",
    "    with open(test, \"r\") as file:\n",
    "        r_pgr_test = json.load(file)\n",
    "\n",
    "    def read_pagerank_json(json, u, v):\n",
    "        key = str(u)+\"_\"+str(v)\n",
    "        if key in json.keys():\n",
    "            return json[key]\n",
    "\n",
    "    # append to dataframes\n",
    "    train_tf = train_tf.assign(root_pagerank = lambda df_: [read_pagerank_json(r_pgr_trainval, u, v) for u, v in zip(df_.node1, df_.node2)])\n",
    "    val_tf =     val_tf.assign(root_pagerank = lambda df_: [read_pagerank_json(r_pgr_trainval, u, v) for u, v in zip(df_.node1, df_.node2)])\n",
    "    test_tf  =  test_tf.assign(root_pagerank = lambda df_: [read_pagerank_json(r_pgr_test, u, v) for u, v in zip(df_.node1, df_.node2)])\n",
    "\n",
    "    # which cols we want to use for link prediction\n",
    "    cols = [\"root_pagerank\"]\n",
    "\n",
    "    methods = [\"rank_avg\"]\n",
    "    threshs = [\"thresh\"]\n",
    "\n",
    "    # generate all combinations of columns in cols\n",
    "    sampled_cols = []\n",
    "    for n in range(1, len(cols) + 1):\n",
    "        sampled_cols += list([c for c in combinations(cols, n)])\n",
    "\n",
    "    for s, m, t in tqdm(product(sampled_cols, methods, threshs)):\n",
    "        y_train_hat = compute_score(X_train, s, m, t)\n",
    "        y_val_hat   = compute_score(X_val, s, m, t)\n",
    "        trn_acc     = accuracy_score(y_train, y_train_hat)\n",
    "        val_acc     = accuracy_score(y_val, y_val_hat)\n",
    "        \n",
    "        y_test_hat  = compute_score(X_test, s, m, t)\n",
    "        tst_acc     = accuracy_score(enriched_test_tf.y, y_test_hat)\n",
    "        res[(s, m, t, damp, e)] = {\"trn_acc\": trn_acc, \"val_acc\": val_acc, \"test_acc\": tst_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2df74050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 0.5, 0.0001, ('root_pagerank',), rank_avg, thresh\n",
      "Train Accuracy 0.99761, Val Accuracy 0.71811, Test Accuracy 0.74145 \n",
      "\n",
      "using 0.5, 1e-06, ('root_pagerank',), rank_avg, thresh\n",
      "Train Accuracy 0.99761, Val Accuracy 0.71811, Test Accuracy 0.74145 \n",
      "\n",
      "using 0.75, 0.0001, ('root_pagerank',), rank_avg, thresh\n",
      "Train Accuracy 0.99761, Val Accuracy 0.71811, Test Accuracy 0.74145 \n",
      "\n",
      "using 0.75, 1e-06, ('root_pagerank',), rank_avg, thresh\n",
      "Train Accuracy 0.99761, Val Accuracy 0.71811, Test Accuracy 0.74145 \n",
      "\n",
      "using 0.9, 0.0001, ('root_pagerank',), rank_avg, thresh\n",
      "Train Accuracy 0.99761, Val Accuracy 0.71811, Test Accuracy 0.74145 \n",
      "\n",
      "using 0.9, 1e-06, ('root_pagerank',), rank_avg, thresh\n",
      "Train Accuracy 0.99761, Val Accuracy 0.71811, Test Accuracy 0.74145 \n",
      "\n",
      "using 0.95, 0.0001, ('root_pagerank',), rank_avg, thresh\n",
      "Train Accuracy 0.99761, Val Accuracy 0.71811, Test Accuracy 0.74145 \n",
      "\n",
      "using 0.95, 1e-06, ('root_pagerank',), rank_avg, thresh\n",
      "Train Accuracy 0.99761, Val Accuracy 0.71811, Test Accuracy 0.74145 \n",
      "\n",
      "using 0.99, 0.0001, ('root_pagerank',), rank_avg, thresh\n",
      "Train Accuracy 0.99761, Val Accuracy 0.71811, Test Accuracy 0.74145 \n",
      "\n",
      "using 0.99, 1e-06, ('root_pagerank',), rank_avg, thresh\n",
      "Train Accuracy 0.99761, Val Accuracy 0.71811, Test Accuracy 0.74145 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordered_res = (sorted(res.items(), key = lambda kv: kv[1][\"val_acc\"], reverse = True))\n",
    "\n",
    "for (col, m, t, damp, e), val_dict in ordered_res[0:30]:\n",
    "    print(f\"using {damp}, {e}, {col}, {m}, {t}\")\n",
    "    print(f\"Train Accuracy {round(val_dict['trn_acc'], 5)}, Val Accuracy {round(val_dict['val_acc'], 5)}, Test Accuracy {round(val_dict['test_acc'], 5)} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "197ac983",
   "metadata": {},
   "source": [
    "Apparently hyperparam tuning of pagerank has absolutely no influence on overall score. When investigating the files, it is clear that the pagerank values change quite a lot -- but the global ordering of the pagerank scores of the edges is kept."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0eecae55",
   "metadata": {},
   "source": [
    "### 3. SimRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a785877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run simrank on G and G_train for each node\n",
    "simrank_test, simrank_trainval = prepData.get_simrank(G, G_train, test_tf, trainval_tf)\n",
    "\n",
    "# save resulting dictionaries in json files\n",
    "with open(\"data/simrank_trainval.json\", \"w\") as file:\n",
    "    json.save(simrank_trainval, file)\n",
    "with open(\"data/simrank_test.json\", \"w\") as file:\n",
    "    json.save(simrank_test, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "edc5d5641674580b35290ba45bd16007251669062615a59c5f9a5e5dd7884ea6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
