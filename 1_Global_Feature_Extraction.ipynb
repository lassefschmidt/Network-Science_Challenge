{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3f9796",
   "metadata": {},
   "source": [
    "# Machine Learning in Network Science\n",
    "Group Challenge\n",
    "\n",
    "***\n",
    "by: Leonardo Basili, Paul Bédier, Lasse Schmidt\n",
    "\n",
    "within: MS Data Sciences & Business Analytics\n",
    "\n",
    "at: CentraleSupélec & ESSEC Business School\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a46be5a",
   "metadata": {},
   "source": [
    "This notebook covers global graph feature extraction such as Rooted Pagerank and SimRank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f241a1",
   "metadata": {},
   "source": [
    "### 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98e82605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util.autoencoder' from 'c:\\\\Users\\\\pbedi\\\\Documents\\\\GitHub\\\\Network-Science_Challenge\\\\util\\\\autoencoder.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(analyseData)\n",
    "reload(prepData)\n",
    "reload(loadData)\n",
    "reload(modeling)\n",
    "reload(autoenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ffae4f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# import own scripts\n",
    "import util.analyse_Data as analyseData\n",
    "import util.preprocess_Data as prepData\n",
    "import util.load_Data as loadData\n",
    "import util.modeling as modeling\n",
    "import util.autoencoder as autoenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c6ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic stuff\n",
    "from itertools import product, combinations\n",
    "from collections import OrderedDict\n",
    "\n",
    "# parse & handle data\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx # graph data\n",
    "import sknetwork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74f20e78",
   "metadata": {},
   "source": [
    "### 2. Rooted Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c682248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive edges for training: 4174\n",
      "Number of positive edges for validation: 1043\n",
      "Number of edges in original graph: 5217\n",
      "Number of edges in training graph: 4174\n",
      "The graph is connected\n",
      "Enriching train data...\n",
      "Enriching validation data...\n",
      "Enriching test data...\n"
     ]
    }
   ],
   "source": [
    "# might take up to a few minutes\n",
    "(G, G_train, node_info,\n",
    " train_tf, val_tf, trainval_tf,\n",
    " test, test_tf,\n",
    " X_train, y_train, X_val, y_val, X_trainval, y_trainval,\n",
    " X_test) = loadData.load_transform(testing_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f7777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run rooted pagerank on G and G_train for each source node as root\n",
    "pagerank_G_train = [prepData.rooted_pagerank(G_train, root) for root in trainval_tf.node1]\n",
    "pagerank_G = [prepData.rooted_pagerank(G, root) for root in test_tf.node1]\n",
    "\n",
    "# generate dictionaries\n",
    "pagerank_trainval = dict()\n",
    "pagerank_test = dict()\n",
    "for u, v in zip(trainval_tf.node1, trainval_tf.node2):\n",
    "    pagerank_trainval[str(u)+\"_\"+str(v)] = pagerank_G_train[str(u)][str(v)]\n",
    "for u, v in zip(test_tf.node1, test_tf.node2):\n",
    "    pagerank_test[str(u)+\"_\"+str(v)] = pagerank_G[str(u)][str(v)]\n",
    "\n",
    "# save dictionaries in json files\n",
    "with open(\"data/pagerank_trainval.json\", \"w\") as file:\n",
    "    json.save(pagerank_trainval, file)\n",
    "with open(\"data/pagerank_test.json\", \"w\") as file:\n",
    "    json.save(pagerank_test, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0eecae55",
   "metadata": {},
   "source": [
    "### 3. SimRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a785877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run simrank on G and G_train for each node\n",
    "simrank_test, simrank_trainval = prepData.get_simrank(G, G_train, test_tf, trainval_tf)\n",
    "\n",
    "# save resulting dictionaries in json files\n",
    "with open(\"data/simrank_trainval.json\", \"w\") as file:\n",
    "    json.save(simrank_trainval, file)\n",
    "with open(\"data/simrank_test.json\", \"w\") as file:\n",
    "    json.save(simrank_test, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "edc5d5641674580b35290ba45bd16007251669062615a59c5f9a5e5dd7884ea6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
